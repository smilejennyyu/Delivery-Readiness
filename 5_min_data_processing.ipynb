{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-0kqbji0k because the default path (/home/ubuntu/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
    }
   ],
   "source": [
    "from src.utils import data_load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.s3_utils import pandas_from_csv_s3\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import json  \n",
    "import math\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {'oura_sleep', 'oura_activity', 'birth'}\n",
    "data = data_load(data_keys=keys, wave=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oura_sleep_list = ['hr_5min', 'rmssd_5min', 'hypnogram_5min']\n",
    "oura_activity_list = ['class_5min', 'met_1min']\n",
    "birth_list = ['user_id', 'birth_date', 'birth_scheduled', 'birth_gestage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "oura_df = data['oura_sleep'][['user_id', 'date'] + oura_sleep_list]\n",
    "oura_activity = data['oura_activity'][['user_id', 'date'] + oura_activity_list]\n",
    "oura_df = pd.merge(oura_df, oura_activity, on=['user_id', 'date'], how='inner')\n",
    "oura_df['date'] = pd.to_datetime(oura_df['date'])\n",
    "birth_df = data['birth'][birth_list]\n",
    "birth_df['birth_date'] = pd.to_datetime(birth_df['birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['id', 'user_id', 'identity_id', 'created_at', 'updated_at',\n       'retrieved_at', 'subsource', 'event_date', 'awake', 'bedtime_end',\n       'bedtime_end_delta', 'bedtime_start', 'bedtime_start_delta',\n       'breath_average', 'deep', 'duration', 'efficiency', 'hr_5min',\n       'hr_average', 'hr_lowest', 'hypnogram_5min', 'is_longest', 'light',\n       'midpoint_at_delta', 'midpoint_time', 'onset_latency', 'period_id',\n       'rem', 'restless', 'rmssd', 'rmssd_5min', 'score', 'score_alignment',\n       'score_deep', 'score_disturbances', 'score_efficiency', 'score_latency',\n       'score_rem', 'score_total', 'temperature_delta',\n       'temperature_deviation', 'temperature_trend_deviation', 'timezone',\n       'total', 'date'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data['oura_sleep'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_str_5min(series, trim_size):\n",
    "    \"\"\"\n",
    "    Process string into list\n",
    "\n",
    "    :param series: (Type - str in Pandas Series) The string in each row of the Pandas Series\n",
    "    E.g. \"453\" -> [4, 5, 3] OR \"[32, 43, 21]\" -> [32, 43, 21]\n",
    "    \"\"\"\n",
    "    if isinstance(series, str):\n",
    "        series = series.replace('\"', '')\n",
    "        if '[' in series:\n",
    "            lst = json.loads(series)\n",
    "        else:\n",
    "            lst = [int(x) for x in list(series)]\n",
    "        if len(lst) < trim_size:\n",
    "            return float('nan')\n",
    "        else:\n",
    "            lst = lst[:trim_size]\n",
    "            lst = pd.Series(lst).replace(0, float('nan'))\n",
    "            lst = lst.interpolate().backfill()\n",
    "            if pd.isna(lst).any():\n",
    "                return float('nan')\n",
    "            else:\n",
    "                return lst.tolist()\n",
    "    elif isinstance(series, list):\n",
    "        pass\n",
    "\n",
    "def process_str_1min(series, trim_size):\n",
    "    \"\"\"\n",
    "    Process string into list\n",
    "\n",
    "    :param series: (Type - str in Pandas Series) The string in each row of the Pandas Series\n",
    "    E.g. \"453\" -> [4, 5, 3] OR \"[32, 43, 21]\" -> [32, 43, 21]\n",
    "    \"\"\"\n",
    "    if isinstance(series, str):\n",
    "        series = series.replace('\"', '')\n",
    "        result = []\n",
    "        if '[' in series:\n",
    "            lst = json.loads(series)\n",
    "        else:\n",
    "            lst = [int(x) for x in list(series)]\n",
    "        if len(lst) < trim_size * 5:\n",
    "            return float('nan')\n",
    "        else:\n",
    "            for i in range(0, len(lst) - 5 + 1, 5):\n",
    "                if i == trim_size * 5:\n",
    "                    break\n",
    "                result.append(sum(lst[i : i+5]) / 5)\n",
    "            result = pd.Series(result)\n",
    "            result = result.interpolate().backfill()\n",
    "            if pd.isna(result).any():\n",
    "                return float('nan')\n",
    "            else:\n",
    "                return result.tolist()\n",
    "    elif isinstance(series, list):\n",
    "        pass\n",
    "\n",
    "def process_min_data(df, field_name, trim_size=50):\n",
    "    \"\"\"\n",
    "    Process min-level data. E.g., 5min, 1min data etc.\n",
    "\n",
    "    :param df: (Type - Pandas DataFrame) The DataFrame that needs to be processed.\n",
    "    :param field_name: (Type - List) A list of field names that needs to be processed.\n",
    "    \"\"\"\n",
    "    # df[field_name] = df[field_name].apply(process_str_5min)\n",
    "    if \"5min\" in field_name:\n",
    "        df[field_name] = df[field_name].apply(process_str_5min, trim_size=trim_size)\n",
    "    elif \"1min\" in field_name:\n",
    "        df[field_name] = df[field_name].apply(process_str_1min, trim_size=trim_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_data = defaultdict(list,{ k:[] for k in oura_sleep_list + oura_activity_list + ['user_id', 'start_date'] })\n",
    "delta = 3\n",
    "start = 5\n",
    "for uid in birth_df['user_id'].unique():\n",
    "    df = oura_df.loc[oura_df['user_id'] == uid].sort_values(by='date')\n",
    "    if len(df) > 0:\n",
    "        for slide_i in range(start - delta + 1):\n",
    "            birth_date = birth_df.loc[birth_df['user_id'] == uid]['birth_date'].tolist()[0]\n",
    "            birth_scheduled = birth_df.loc[birth_df['user_id'] == uid]['birth_scheduled'].tolist()[0]\n",
    "            if birth_scheduled == 2:\n",
    "                start_date = birth_date + pd.to_timedelta(-start + slide_i + 1, unit='d')\n",
    "                end_date = start_date + pd.to_timedelta(delta, unit='d')\n",
    "                each_df = df[(df['date'] >= start_date) & (df['date'] < end_date)]\n",
    "                if len(each_df) == delta:        \n",
    "                    process_min_data(each_df, 'hr_5min')\n",
    "                    process_min_data(each_df, 'rmssd_5min')\n",
    "                    process_min_data(each_df, 'hypnogram_5min')\n",
    "                    process_min_data(each_df, 'class_5min')\n",
    "                    process_min_data(each_df, 'met_1min')\n",
    "                    each_df = each_df.dropna()\n",
    "                    if len(each_df) == delta:\n",
    "                        clean_positive_data['user_id'].append(int(uid))   \n",
    "                        clean_positive_data['start_date'].append((birth_date - start_date).days)\n",
    "                        for col in oura_sleep_list + oura_activity_list:\n",
    "                            clean_positive_data[col].append(np.array(each_df[col].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "269 131\n"
    }
   ],
   "source": [
    "print(len(clean_positive_data['user_id']), len(set(clean_positive_data['user_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_user in range(len(clean_positive_data['user_id'])):\n",
    "    for feature in oura_sleep_list:\n",
    "        clean_positive_data[feature][each_user] = np.concatenate(tuple(clean_positive_data[feature][each_user]), axis=0)\n",
    "    for feature in oura_activity_list:\n",
    "        clean_positive_data[feature][each_user] = np.concatenate(tuple(clean_positive_data[feature][each_user]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pick(start_date, end_date, duration):\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    random_date = start_date + datetime.timedelta(days=random_number_of_days)\n",
    "\n",
    "    return [random_date, random_date + datetime.timedelta(days=duration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['hr_5min', 'rmssd_5min', 'hypnogram_5min', 'class_5min', 'met_1min']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "oura_sleep_list + oura_activity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_negative_data_same = defaultdict(list,{ k:[] for k in oura_sleep_list + oura_activity_list + ['user_id'] })\n",
    "before_days = 3\n",
    "cut_off_day = 30\n",
    "for uid in set(clean_positive_data['user_id']):\n",
    "    df = oura_df.loc[oura_df['user_id'] == uid].sort_values(by='date')\n",
    "    if len(df) > 0:\n",
    "        birth_date = birth_df.loc[birth_df['user_id'] == uid]['birth_date'].tolist()[0]\n",
    "        birth_scheduled = birth_df.loc[birth_df['user_id'] == uid]['birth_scheduled'].tolist()[0]\n",
    "        if birth_scheduled == 2:\n",
    "            # end_date = birth_date + pd.to_timedelta(-start, unit='d')\n",
    "            start_date = end_date + pd.to_timedelta(-cut_off_day, unit='d')\n",
    "            start_date = df['date'].min()\n",
    "            for count in range(1000):\n",
    "                random_days = random_pick(start_date, end_date, delta)\n",
    "                each_df = df[(df['date'] >= random_days[0]) & (df['date'] < random_days[1])]\n",
    "                if len(each_df) >= before_days:\n",
    "                    process_min_data(each_df, 'hr_5min')\n",
    "                    process_min_data(each_df, 'rmssd_5min')\n",
    "                    process_min_data(each_df, 'hypnogram_5min')\n",
    "                    process_min_data(each_df, 'class_5min')\n",
    "                    process_min_data(each_df, 'met_1min')\n",
    "                    each_df = each_df.dropna()\n",
    "                    if len(each_df) == delta:\n",
    "                        clean_negative_data_same['user_id'].append(int(uid))   \n",
    "                        clean_negative_data_same['start_date'].append((birth_date - random_days[0]).days)\n",
    "                        for col in oura_sleep_list + oura_activity_list:\n",
    "                            clean_negative_data_same[col].append(np.array(each_df[col].tolist()))\n",
    "                        break\n",
    "                else:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_user in range(len(clean_negative_data_same['user_id'])):\n",
    "    for feature in oura_sleep_list:\n",
    "        clean_negative_data_same[feature][each_user] = np.concatenate(tuple(clean_negative_data_same[feature][each_user]), axis=0)\n",
    "    for feature in oura_activity_list:\n",
    "        clean_negative_data_same[feature][each_user] = np.concatenate(tuple(clean_negative_data_same[feature][each_user]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_negative_data_diff = defaultdict(list,{ k:[] for k in oura_sleep_list + oura_activity_list + ['user_id'] })\n",
    "for uid in birth_df['user_id'].unique():\n",
    "    if uid not in clean_positive_data['user_id']:\n",
    "        df = oura_df.loc[oura_df['user_id'] == uid].sort_values(by='date')\n",
    "        if len(df) > 0:\n",
    "            birth_date = birth_df.loc[birth_df['user_id'] == uid]['birth_date'].tolist()[0]\n",
    "            birth_scheduled = birth_df.loc[birth_df['user_id'] == uid]['birth_scheduled'].tolist()[0]\n",
    "            if birth_scheduled == 2:\n",
    "                end_date = birth_date + pd.to_timedelta(-start, unit='d')\n",
    "                # start_date = df['date'].min()\n",
    "                start_date = end_date + pd.to_timedelta(-cut_off_day, unit='d')\n",
    "                if start_date < end_date:\n",
    "                    for count in range(1000):  \n",
    "                        random_days = random_pick(start_date, end_date, delta)\n",
    "                        each_df = df[(df['date'] >= random_days[0]) & (df['date'] < random_days[1])]\n",
    "                        if len(each_df) >= before_days:\n",
    "                            process_min_data(each_df, 'hr_5min')\n",
    "                            process_min_data(each_df, 'rmssd_5min')\n",
    "                            process_min_data(each_df, 'hypnogram_5min')\n",
    "                            process_min_data(each_df, 'class_5min')\n",
    "                            process_min_data(each_df, 'met_1min')\n",
    "                            each_df = each_df.dropna()\n",
    "                            if len(each_df) == delta:\n",
    "                                clean_negative_data_diff['user_id'].append(int(uid))   \n",
    "                                clean_negative_data_diff['start_date'].append((birth_date - random_days[0]).days)\n",
    "                                for col in oura_sleep_list + oura_activity_list:\n",
    "                                    clean_negative_data_diff[col].append(np.array(each_df[col].tolist()))\n",
    "                                break\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "                    print(start_date, end_date, birth_date, uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_user in range(len(clean_negative_data_diff['user_id'])):\n",
    "    for feature in oura_sleep_list:\n",
    "        clean_negative_data_diff[feature][each_user] = np.concatenate(tuple(clean_negative_data_diff[feature][each_user]), axis=0)\n",
    "    for feature in oura_activity_list:\n",
    "        clean_negative_data_diff[feature][each_user] = np.concatenate(tuple(clean_negative_data_diff[feature][each_user]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "150\n150\n150\n"
    }
   ],
   "source": [
    "print(len(clean_negative_data_same['hr_5min'][0]))\n",
    "print(len(clean_negative_data_diff['hr_5min'][0]))\n",
    "print(len(clean_positive_data['hr_5min'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_data['user_id'] = np.array(clean_positive_data['user_id'])\n",
    "clean_negative_data_diff['user_id'] = np.array(clean_negative_data_diff['user_id'])\n",
    "clean_negative_data_same['user_id'] = np.array(clean_negative_data_same['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fold 0\nFold 1\nFold 2\nFold 3\nFold 4\nFold 5\nFold 6\nFold 7\nFold 8\nFold 9\n"
    }
   ],
   "source": [
    "# k-fold users that have both pos and neg windows\n",
    "train = {'X': [], 'y': [], 'uid': [], 'start_date': [], 'feature_name': []}\n",
    "test = {'X': [], 'y': [], 'uid': [], 'start_date': [], 'feature_name': []}\n",
    "\n",
    "both_users = list(set(clean_positive_data['user_id']))\n",
    "kf_both = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for fold_i, (train_index, test_index) in enumerate(kf_both.split(both_users)):\n",
    "    print(f\"Fold {fold_i}\")\n",
    "    train_X_lst, train_y_lst, train_uid_lst, train_start_date_lst = [], [], [], []\n",
    "    test_X_lst, test_y_lst, test_uid_lst, test_start_date_lst = [], [], [], []\n",
    "    train_ids = list(np.array(both_users)[train_index]) # user ids of training \n",
    "    test_ids = list(np.array(both_users)[test_index]) # user ids of testing\n",
    "\n",
    "    # initialize \n",
    "    train_indices_pos = []\n",
    "    train_indices_neg_same = []\n",
    "    test_indices_pos = []\n",
    "    test_indices_neg_same = []\n",
    "    # get train and test user ids\n",
    "    for x in train_ids:\n",
    "        train_indices_pos.extend(np.where(clean_positive_data['user_id']==x)[0].tolist())\n",
    "        train_indices_neg_same.extend(np.where(clean_negative_data_same['user_id']==x)[0].tolist())\n",
    "    for x in test_ids:\n",
    "        test_indices_pos.extend(np.where(clean_positive_data['user_id']==x)[0].tolist())\n",
    "        test_indices_neg_same.extend(np.where(clean_negative_data_same['user_id']==x)[0].tolist())\n",
    "\n",
    "    # append train data for both pos and neg classes\n",
    "    for i in train_indices_neg_same:\n",
    "        # train_X_lst.append(np.vstack([clean_negative_data_same['hr_5min'][i], clean_negative_data_same['rmssd_5min'][i], clean_negative_data_same['hypnogram_5min'][i], clean_negative_data_same['class_5min'][i], clean_negative_data_same['met_1min'][i]]))\n",
    "        train_X_lst.append(np.vstack([clean_negative_data_same['hr_5min'][i], clean_negative_data_same['rmssd_5min'][i], clean_negative_data_same['hypnogram_5min'][i]]))\n",
    "        train_y_lst.append(0)\n",
    "        train_uid_lst.append(clean_negative_data_same['user_id'][i])\n",
    "        train_start_date_lst.append(clean_negative_data_same['start_date'][i])\n",
    "    for i in train_indices_pos:\n",
    "        # train_X_lst.append(np.vstack([clean_positive_data['hr_5min'][i], clean_positive_data['rmssd_5min'][i], clean_positive_data['hypnogram_5min'][i], clean_positive_data['class_5min'][i], clean_positive_data['met_1min'][i]]))\n",
    "        train_X_lst.append(np.vstack([clean_positive_data['hr_5min'][i], clean_positive_data['rmssd_5min'][i], clean_positive_data['hypnogram_5min'][i]]))\n",
    "        train_y_lst.append(1)\n",
    "        train_uid_lst.append(clean_positive_data['user_id'][i])\n",
    "        train_start_date_lst.append(clean_positive_data['start_date'][i])\n",
    "\n",
    "    # append test data for both pos and neg classes\n",
    "    for i in test_indices_neg_same:\n",
    "        # test_X_lst.append(np.vstack([clean_negative_data_same['hr_5min'][i], clean_negative_data_same['rmssd_5min'][i], clean_negative_data_same['hypnogram_5min'][i], clean_negative_data_same['class_5min'][i], clean_negative_data_same['met_1min'][i]]))\n",
    "\n",
    "        # specifically append this to train set, this is to simulate the window prediction ability given negative windows\n",
    "        train_X_lst.append(np.vstack([clean_negative_data_same['hr_5min'][i], clean_negative_data_same['rmssd_5min'][i], clean_negative_data_same['hypnogram_5min'][i]]))\n",
    "        train_y_lst.append(0)\n",
    "        train_uid_lst.append(clean_negative_data_same['user_id'][i])\n",
    "        train_start_date_lst.append(clean_negative_data_same['start_date'][i])\n",
    "\n",
    "    for i in test_indices_pos:\n",
    "        # test_X_lst.append(np.vstack([clean_positive_data['hr_5min'][i], clean_positive_data['rmssd_5min'][i], clean_positive_data['hypnogram_5min'][i], clean_positive_data['class_5min'][i], clean_positive_data['met_1min'][i]]))\n",
    "        test_X_lst.append(np.vstack([clean_positive_data['hr_5min'][i], clean_positive_data['rmssd_5min'][i], clean_positive_data['hypnogram_5min'][i]]))\n",
    "        test_y_lst.append(1)\n",
    "        test_uid_lst.append(clean_positive_data['user_id'][i])\n",
    "        test_start_date_lst.append(clean_positive_data['start_date'][i])\n",
    "    \n",
    "    # append both train and test data to the main data dict\n",
    "    train['X'].append(train_X_lst)\n",
    "    train['y'].append(train_y_lst)\n",
    "    train['uid'].append(train_uid_lst)\n",
    "    train['start_date'].append(train_start_date_lst)\n",
    "    test['X'].append(test_X_lst)\n",
    "    test['y'].append(test_y_lst)\n",
    "    test['uid'].append(test_uid_lst)\n",
    "    test['start_date'].append(test_start_date_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fold 0\nFold 1\nFold 2\nFold 3\nFold 4\nFold 5\nFold 6\nFold 7\nFold 8\nFold 9\n"
    }
   ],
   "source": [
    "# k-fold users that only have neg windows\n",
    "only_neg_users = clean_negative_data_diff['user_id']\n",
    "kf_only = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for fold_i, (train_index, test_index) in enumerate(kf_only.split(only_neg_users)):\n",
    "    print(f\"Fold {fold_i}\")\n",
    "    # initialize \n",
    "    train_indices_neg_diff = []\n",
    "    test_indices_neg_diff = []\n",
    "    train_ids = list(np.array(only_neg_users)[train_index]) # user ids of training \n",
    "    test_ids = list(np.array(only_neg_users)[test_index]) # user ids of testing\n",
    "\n",
    "    # get train and test user ids\n",
    "    for x in train_ids:\n",
    "        train_indices_neg_diff.extend(np.where(clean_negative_data_diff['user_id']==x)[0].tolist())\n",
    "    for x in test_ids:\n",
    "        test_indices_neg_diff.extend(np.where(clean_negative_data_diff['user_id']==x)[0].tolist())\n",
    "\n",
    "    # append train and test data for both neg diff classes\n",
    "    for i in train_indices_neg_diff:\n",
    "        # train['X'][fold_i].append(np.vstack([clean_negative_data_diff['hr_5min'][i], clean_negative_data_diff['rmssd_5min'][i], clean_negative_data_diff['hypnogram_5min'][i], clean_negative_data_diff['class_5min'][i], clean_negative_data_diff['met_1min'][i]]))\n",
    "        train['X'][fold_i].append(np.vstack([clean_negative_data_diff['hr_5min'][i], clean_negative_data_diff['rmssd_5min'][i], clean_negative_data_diff['hypnogram_5min'][i]]))\n",
    "        train['y'][fold_i].append(0)\n",
    "        train['uid'][fold_i].append(clean_negative_data_diff['user_id'][i])\n",
    "        train['start_date'][fold_i].append(clean_negative_data_diff['start_date'][i])\n",
    "    for i in test_indices_neg_diff:\n",
    "        # test['X'][fold_i].append(np.vstack([clean_negative_data_diff['hr_5min'][i], clean_negative_data_diff['rmssd_5min'][i], clean_negative_data_diff['hypnogram_5min'][i], clean_negative_data_diff['class_5min'][i], clean_negative_data_diff['met_1min'][i]]))\n",
    "        # specifically append this to train set, this is to simulate the window prediction ability given negative windows\n",
    "        train['X'][fold_i].append(np.vstack([clean_negative_data_diff['hr_5min'][i], clean_negative_data_diff['rmssd_5min'][i], clean_negative_data_diff['hypnogram_5min'][i]]))\n",
    "        train['y'][fold_i].append(0)\n",
    "        train['uid'][fold_i].append(clean_negative_data_diff['user_id'][i])\n",
    "        train['start_date'][fold_i].append(clean_negative_data_diff['start_date'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "for fold_i in range(len(train['X'])):\n",
    "    train['X'][fold_i] = np.stack(train['X'][fold_i])\n",
    "    # each_train = {'X': train['X'][fold_i], 'y': train['y'][fold_i], 'uid': train['uid'][fold_i], 'start_date': train['start_date'][fold_i], 'feature_name': ['hr_5min', 'rmssd_5min', 'hypnogram_5min', 'class_5min', 'met_5min']}\n",
    "    each_train = {'X': train['X'][fold_i], 'y': train['y'][fold_i], 'uid': train['uid'][fold_i], 'start_date': train['start_date'][fold_i], 'feature_name': ['hr_5min', 'rmssd_5min', 'hypnogram_5min']}\n",
    "    # with open(f'/repos/Delivery-Readiness/data/5min_new_split_non_schedule/largest_window/train_{fold_i}.pickle', 'wb') as handle:\n",
    "    with open(f'/repos/Delivery-Readiness/data/5min_new_split_non_schedule/{cut_off_day}days/train_{fold_i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(each_train, handle)\n",
    "for fold_i in range(len(test['X'])):\n",
    "    test['X'][fold_i] = np.stack(test['X'][fold_i])\n",
    "    # each_test = {'X': test['X'][fold_i], 'y': test['y'][fold_i], 'uid': test['uid'][fold_i], 'start_date': test['start_date'][fold_i], 'feature_name': ['hr_5min', 'rmssd_5min', 'hypnogram_5min', 'class_5min', 'met_5min']}\n",
    "    each_test = {'X': test['X'][fold_i], 'y': test['y'][fold_i], 'uid': test['uid'][fold_i], 'start_date': test['start_date'][fold_i], 'feature_name': ['hr_5min', 'rmssd_5min', 'hypnogram_5min']}\n",
    "    # with open(f'/repos/Delivery-Readiness/data/5min_new_split_non_schedule/largest_window/test_{fold_i}.pickle', 'wb') as handle:\n",
    "    with open(f'/repos/Delivery-Readiness/data/5min_new_split_non_schedule/{cut_off_day}days/test_{fold_i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(each_test, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391664bitmyenvcondac91407650cb346e5ae08b4a0d62a0b53",
   "display_name": "Python 3.9.16 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}