{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import data_load\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.s3_utils import pandas_from_csv_s3\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = {'oura_sleep', 'oura_activity', 'birth'}\n",
    "data = data_load(data_keys=keys, wave=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "oura_sleep_list = ['hr_lowest', 'hr_average', 'rmssd', 'deep', 'light', 'awake', 'rem']\n",
    "oura_activity_list = []\n",
    "birth_list = ['user_id', 'birth_date', 'birth_scheduled', 'birth_gestage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "oura_df = data['oura_sleep'][['user_id', 'date'] + oura_sleep_list]\n",
    "oura_activity = data['oura_activity'][['user_id', 'date'] + oura_activity_list]\n",
    "oura_df = pd.merge(oura_df, oura_activity, on=['user_id', 'date'], how='inner')\n",
    "oura_df['date'] = pd.to_datetime(oura_df['date'])\n",
    "birth_df = data['birth'][birth_list]\n",
    "birth_df['birth_date'] = pd.to_datetime(birth_df['birth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Index(['id', 'user_id', 'identity_id', 'created_at', 'updated_at',\n       'retrieved_at', 'subsource', 'event_date', 'awake', 'bedtime_end',\n       'bedtime_end_delta', 'bedtime_start', 'bedtime_start_delta',\n       'breath_average', 'deep', 'duration', 'efficiency', 'hr_5min',\n       'hr_average', 'hr_lowest', 'hypnogram_5min', 'is_longest', 'light',\n       'midpoint_at_delta', 'midpoint_time', 'onset_latency', 'period_id',\n       'rem', 'restless', 'rmssd', 'rmssd_5min', 'score', 'score_alignment',\n       'score_deep', 'score_disturbances', 'score_efficiency', 'score_latency',\n       'score_rem', 'score_total', 'temperature_delta',\n       'temperature_deviation', 'temperature_trend_deviation', 'timezone',\n       'total', 'date'],\n      dtype='object')"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "data['oura_sleep'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_data = defaultdict(list,{ k:[] for k in oura_sleep_list + oura_activity_list + ['user_id', 'start_date'] })\n",
    "delta = 3\n",
    "start = 5\n",
    "for uid in birth_df['user_id'].unique():\n",
    "    df = oura_df.loc[oura_df['user_id'] == uid].sort_values(by='date')\n",
    "    if len(df) > 0:\n",
    "        for slide_i in range(start - delta + 1):\n",
    "            birth_date = birth_df.loc[birth_df['user_id'] == uid]['birth_date'].tolist()[0]\n",
    "            birth_scheduled = birth_df.loc[birth_df['user_id'] == uid]['birth_scheduled'].tolist()[0]\n",
    "            if birth_scheduled == 2:\n",
    "                start_date = birth_date + pd.to_timedelta(-start + slide_i + 1, unit='d')\n",
    "                end_date = start_date + pd.to_timedelta(delta, unit='d')\n",
    "                each_df = df[(df['date'] >= start_date) & (df['date'] < end_date)]\n",
    "                if len(each_df) == delta:   \n",
    "                    each_df = each_df.dropna()\n",
    "                    if len(each_df) == delta:\n",
    "                        clean_positive_data['user_id'].append(int(uid))   \n",
    "                        clean_positive_data['start_date'].append((birth_date - start_date).days)\n",
    "                        for col in oura_sleep_list + oura_activity_list:\n",
    "                            clean_positive_data[col].append(np.array(each_df[col].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "133 65\n"
    }
   ],
   "source": [
    "print(len(clean_positive_data['user_id']), len(set(clean_positive_data['user_id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([72.79, 73.41, 68.65])"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "clean_positive_data['hr_average'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pick(start_date, end_date, duration):\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    random_date = start_date + datetime.timedelta(days=random_number_of_days)\n",
    "\n",
    "    return [random_date, random_date + datetime.timedelta(days=duration)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['hr_lowest', 'hr_average', 'rmssd', 'deep', 'light', 'awake', 'rem']"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "oura_sleep_list + oura_activity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_day = 30\n",
    "clean_negative_data_same = defaultdict(list,{ k:[] for k in oura_sleep_list + oura_activity_list + ['user_id'] })\n",
    "for uid in set(clean_positive_data['user_id']):\n",
    "    df = oura_df.loc[oura_df['user_id'] == uid].sort_values(by='date')\n",
    "    if len(df) > 0:\n",
    "        birth_date = birth_df.loc[birth_df['user_id'] == uid]['birth_date'].tolist()[0]\n",
    "        birth_scheduled = birth_df.loc[birth_df['user_id'] == uid]['birth_scheduled'].tolist()[0]\n",
    "        if birth_scheduled == 2:\n",
    "            end_date = birth_date + pd.to_timedelta(-start, unit='d')\n",
    "\n",
    "            start_date = df['date'].min()\n",
    "            # start_date = end_date + pd.to_timedelta(-cut_off_day, unit='d')\n",
    "            \n",
    "            for count in range(1000):\n",
    "                random_days = random_pick(start_date, end_date, delta)\n",
    "                each_df = df[(df['date'] >= random_days[0]) & (df['date'] < random_days[1])]\n",
    "                if len(each_df) >= delta:\n",
    "                    each_df = each_df.dropna()\n",
    "                    if len(each_df) == delta:\n",
    "                        clean_negative_data_same['user_id'].append(int(uid))   \n",
    "                        clean_negative_data_same['start_date'].append((birth_date - random_days[0]).days)\n",
    "                        for col in oura_sleep_list + oura_activity_list:\n",
    "                            clean_negative_data_same[col].append(np.array(each_df[col].tolist()))\n",
    "                        break\n",
    "                else:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_negative_data_diff = defaultdict(list,{ k:[] for k in oura_sleep_list + oura_activity_list + ['user_id'] })\n",
    "for uid in birth_df['user_id'].unique():\n",
    "    if uid not in clean_positive_data['user_id']:\n",
    "        df = oura_df.loc[oura_df['user_id'] == uid].sort_values(by='date')\n",
    "        if len(df) > 0:\n",
    "            birth_date = birth_df.loc[birth_df['user_id'] == uid]['birth_date'].tolist()[0]\n",
    "            birth_scheduled = birth_df.loc[birth_df['user_id'] == uid]['birth_scheduled'].tolist()[0]\n",
    "            if birth_scheduled == 2:\n",
    "                end_date = birth_date + pd.to_timedelta(-start, unit='d')\n",
    "\n",
    "                start_date = df['date'].min()\n",
    "                # start_date = end_date + pd.to_timedelta(-cut_off_day, unit='d')\n",
    "\n",
    "                if start_date < end_date:\n",
    "                    for count in range(1000):  \n",
    "                        random_days = random_pick(start_date, end_date, delta)\n",
    "                        each_df = df[(df['date'] >= random_days[0]) & (df['date'] < random_days[1])]\n",
    "                        if len(each_df) >= delta:\n",
    "                            each_df = each_df.dropna()\n",
    "                            if len(each_df) == delta:\n",
    "                                clean_negative_data_diff['user_id'].append(int(uid))   \n",
    "                                clean_negative_data_diff['start_date'].append((birth_date - random_days[0]).days)\n",
    "                                for col in oura_sleep_list + oura_activity_list:\n",
    "                                    clean_negative_data_diff[col].append(np.array(each_df[col].tolist()))\n",
    "                                break\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "                    print(start_date, end_date, birth_date, uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3\n3\n3\n"
    }
   ],
   "source": [
    "print(len(clean_negative_data_same['hr_average'][0]))\n",
    "print(len(clean_negative_data_diff['hr_average'][0]))\n",
    "print(len(clean_positive_data['hr_average'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_positive_data['user_id'] = np.array(clean_positive_data['user_id'])\n",
    "clean_negative_data_diff['user_id'] = np.array(clean_negative_data_diff['user_id'])\n",
    "clean_negative_data_same['user_id'] = np.array(clean_negative_data_same['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "110"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "len(clean_negative_data_same['user_id'].tolist() + clean_negative_data_diff['user_id'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fold 0\nFold 1\nFold 2\nFold 3\nFold 4\nFold 5\nFold 6\nFold 7\nFold 8\nFold 9\n"
    }
   ],
   "source": [
    "# k-fold users that have both pos and neg windows\n",
    "train = {'X': [], 'y': [], 'uid': [], 'start_date': [], 'feature_name': []}\n",
    "test = {'X': [], 'y': [], 'uid': [], 'start_date': [], 'feature_name': []}\n",
    "\n",
    "both_users = list(set(clean_positive_data['user_id']))\n",
    "kf_both = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for fold_i, (train_index, test_index) in enumerate(kf_both.split(both_users)):\n",
    "    print(f\"Fold {fold_i}\")\n",
    "    train_X_lst, train_y_lst, train_uid_lst, train_start_date_lst = [], [], [], []\n",
    "    test_X_lst, test_y_lst, test_uid_lst, test_start_date_lst = [], [], [], []\n",
    "    train_ids = list(np.array(both_users)[train_index]) # user ids of training \n",
    "    test_ids = list(np.array(both_users)[test_index]) # user ids of testing\n",
    "\n",
    "    # initialize \n",
    "    train_indices_pos = []\n",
    "    train_indices_neg_same = []\n",
    "    test_indices_pos = []\n",
    "    test_indices_neg_same = []\n",
    "    # get train and test user ids\n",
    "    for x in train_ids:\n",
    "        train_indices_pos.extend(np.where(clean_positive_data['user_id']==x)[0].tolist())\n",
    "        train_indices_neg_same.extend(np.where(clean_negative_data_same['user_id']==x)[0].tolist())\n",
    "    for x in test_ids:\n",
    "        test_indices_pos.extend(np.where(clean_positive_data['user_id']==x)[0].tolist())\n",
    "        test_indices_neg_same.extend(np.where(clean_negative_data_same['user_id']==x)[0].tolist())\n",
    "\n",
    "    # append train data for both pos and neg classes\n",
    "    for i in train_indices_neg_same:\n",
    "        x_processed = []\n",
    "        for feature in oura_activity_list + oura_sleep_list:\n",
    "            x_processed.append(clean_negative_data_same[feature][i])\n",
    "        train_X_lst.append(np.vstack(x_processed))\n",
    "        train_y_lst.append(0)\n",
    "        train_uid_lst.append(clean_negative_data_same['user_id'][i])\n",
    "        train_start_date_lst.append(clean_negative_data_same['start_date'][i])\n",
    "    for i in train_indices_pos:\n",
    "        x_processed = []\n",
    "        for feature in oura_activity_list + oura_sleep_list:\n",
    "            x_processed.append(clean_positive_data[feature][i])\n",
    "        train_X_lst.append(np.vstack(x_processed))\n",
    "        train_y_lst.append(1)\n",
    "        train_uid_lst.append(clean_positive_data['user_id'][i])\n",
    "        train_start_date_lst.append(clean_positive_data['start_date'][i])\n",
    "\n",
    "    # append test data for both pos and neg classes\n",
    "    # add this to training\n",
    "    for i in test_indices_neg_same:\n",
    "        x_processed = []\n",
    "        for feature in oura_activity_list + oura_sleep_list:\n",
    "            x_processed.append(clean_negative_data_same[feature][i])\n",
    "        train_X_lst.append(np.vstack(x_processed))\n",
    "        train_y_lst.append(0)\n",
    "        train_uid_lst.append(clean_negative_data_same['user_id'][i])\n",
    "        train_start_date_lst.append(clean_negative_data_same['start_date'][i])\n",
    "\n",
    "    for i in test_indices_pos:\n",
    "        x_processed = []\n",
    "        for feature in oura_activity_list + oura_sleep_list:\n",
    "            x_processed.append(clean_positive_data[feature][i])\n",
    "        test_X_lst.append(np.vstack(x_processed))\n",
    "        test_y_lst.append(1)\n",
    "        test_uid_lst.append(clean_positive_data['user_id'][i])\n",
    "        test_start_date_lst.append(clean_positive_data['start_date'][i])\n",
    "    \n",
    "    # append both train and test data to the main data dict\n",
    "    train['X'].append(train_X_lst)\n",
    "    train['y'].append(train_y_lst)\n",
    "    train['uid'].append(train_uid_lst)\n",
    "    train['start_date'].append(train_start_date_lst)\n",
    "    test['X'].append(test_X_lst)\n",
    "    test['y'].append(test_y_lst)\n",
    "    test['uid'].append(test_uid_lst)\n",
    "    test['start_date'].append(test_start_date_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fold 0\nFold 1\nFold 2\nFold 3\nFold 4\nFold 5\nFold 6\nFold 7\nFold 8\nFold 9\n"
    }
   ],
   "source": [
    "# k-fold users that only have neg windows\n",
    "only_neg_users = clean_negative_data_diff['user_id']\n",
    "kf_only = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for fold_i, (train_index, test_index) in enumerate(kf_only.split(only_neg_users)):\n",
    "    print(f\"Fold {fold_i}\")\n",
    "    # initialize \n",
    "    train_indices_neg_diff = []\n",
    "    test_indices_neg_diff = []\n",
    "    train_ids = list(np.array(only_neg_users)[train_index]) # user ids of training \n",
    "    test_ids = list(np.array(only_neg_users)[test_index]) # user ids of testing\n",
    "\n",
    "    # get train and test user ids\n",
    "    for x in train_ids:\n",
    "        train_indices_neg_diff.extend(np.where(clean_negative_data_diff['user_id']==x)[0].tolist())\n",
    "    for x in test_ids:\n",
    "        test_indices_neg_diff.extend(np.where(clean_negative_data_diff['user_id']==x)[0].tolist())\n",
    "\n",
    "    # append train and test data for both neg diff classes\n",
    "    for i in train_indices_neg_diff:\n",
    "        x_processed = []\n",
    "        for feature in oura_activity_list + oura_sleep_list:\n",
    "            x_processed.append(clean_negative_data_diff[feature][i])\n",
    "        train['X'][fold_i].append(np.vstack(x_processed))\n",
    "        train['y'][fold_i].append(0)\n",
    "        train['uid'][fold_i].append(clean_negative_data_diff['user_id'][i])\n",
    "        train['start_date'][fold_i].append(clean_negative_data_diff['start_date'][i])\n",
    "    for i in test_indices_neg_diff:\n",
    "        x_processed = []\n",
    "        for feature in oura_activity_list + oura_sleep_list:\n",
    "            x_processed.append(clean_negative_data_diff[feature][i])\n",
    "        train['X'][fold_i].append(np.vstack(x_processed))\n",
    "        train['y'][fold_i].append(0)\n",
    "        train['uid'][fold_i].append(clean_negative_data_diff['user_id'][i])\n",
    "        train['start_date'][fold_i].append(clean_negative_data_diff['start_date'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_i in range(len(train['X'])):\n",
    "    train['X'][fold_i] = np.stack(train['X'][fold_i])\n",
    "    each_train = {'X': train['X'][fold_i], 'y': train['y'][fold_i], 'uid': train['uid'][fold_i], 'start_date': train['start_date'][fold_i], 'feature_name': oura_activity_list + oura_sleep_list}\n",
    "    # with open(f'/repos/Delivery-Readiness/data/daily_new_split_non_schedule/largest_window/train_{fold_i}.pickle', 'wb') as handle:\n",
    "    with open(f'/repos/Delivery-Readiness/data/daily_new_split_non_schedule/{cut_off_day}days/train_{fold_i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(each_train, handle)\n",
    "for fold_i in range(len(test['X'])):\n",
    "    test['X'][fold_i] = np.stack(test['X'][fold_i])\n",
    "    each_test = {'X': test['X'][fold_i], 'y': test['y'][fold_i], 'uid': test['uid'][fold_i], 'start_date': test['start_date'][fold_i], 'feature_name': oura_activity_list + oura_sleep_list}\n",
    "    # with open(f'/repos/Delivery-Readiness/data/daily_new_split_non_schedule/largest_window/test_{fold_i}.pickle', 'wb') as handle:\n",
    "    with open(f'/repos/Delivery-Readiness/data/daily_new_split_non_schedule/{cut_off_day}days/test_{fold_i}.pickle', 'wb') as handle:\n",
    "        pickle.dump(each_test, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391664bitmyenvcondac91407650cb346e5ae08b4a0d62a0b53",
   "display_name": "Python 3.9.16 64-bit ('myenv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}